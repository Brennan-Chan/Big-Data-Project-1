{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "963e1985",
   "metadata": {},
   "source": [
    "# Project 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed3a468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brennan_Chan1\\Documents\\Virtual Enviornments\\py312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import to_hex\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE, LocallyLinearEmbedding\n",
    "from sklearn.decomposition import PCA, SparsePCA, MiniBatchSparsePCA\n",
    "from umap import UMAP\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "import torch, torch_directml as dml\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "460ac86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backend OK: True\n",
      "using device: privateuseone:0\n",
      "torch device count (dml is logical 1): 1\n"
     ]
    }
   ],
   "source": [
    "# just to test if dml is working\n",
    "print(\"backend OK:\", hasattr(dml, \"device\"))\n",
    "print(\"using device:\", dml.device())\n",
    "print(\"torch device count (dml is logical 1):\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7adb87b",
   "metadata": {},
   "source": [
    "## PCA for Iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65e611cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the iris dataset \n",
    "iris_dat = load_iris()\n",
    "\n",
    "X = iris_dat.data  \n",
    "y = iris_dat.target\n",
    "\n",
    "feature_names = iris_dat.feature_names\n",
    "target_names = iris_dat.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfe49e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-SNE on a dataset\n",
    "def do_tsne(X, n_components=2, method=\"barnes_hut\", perplexity=30, init=\"pca\", random_state=None):\n",
    "\n",
    "    X_proc = X.values if isinstance(X, pd.DataFrame) else np.asarray(X)\n",
    "\n",
    "    tsne = TSNE(\n",
    "        n_components=n_components,\n",
    "        perplexity=perplexity, \n",
    "        init=init, \n",
    "        learning_rate=\"auto\",\n",
    "        method= method, \n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    X_tsne = tsne.fit_transform(X_proc)\n",
    "\n",
    "    return X_tsne\n",
    "\n",
    "# Preform UMAP on a dataset\n",
    "def do_UMAP(X, n_neighbors=15, n_components=2 ,min_dist=0.1, metric='euclidean',\n",
    "             init='spectral', random_state=None):\n",
    "\n",
    "    X_proc = X.values if isinstance(X, pd.DataFrame) else np.asarray(X)\n",
    "\n",
    "    umap = UMAP(\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        n_components=n_components,\n",
    "        init=init,                      #{random}\n",
    "        metric=metric,                  #{cosine}\n",
    "        random_state=random_state,\n",
    "        n_jobs=1\n",
    "    )\n",
    "\n",
    "    X_umap = umap.fit_transform(X_proc)\n",
    "\n",
    "    return X_umap\n",
    "\n",
    "# preform PCA on a dataset \n",
    "def do_PCA(X, n_components=2, whiten=False, svd_solver=\"auto\", iterated_power=\"auto\",\n",
    "           random_state=None, return_model=False):\n",
    "    \n",
    "    X_proc = X.values if isinstance(X, pd.DataFrame) else np.asarray(X)\n",
    "\n",
    "    pca = PCA(\n",
    "        n_components=n_components,\n",
    "        whiten=whiten,\n",
    "        svd_solver=svd_solver,          # {\"auto\",\"full\",\"arpack\",\"randomized\"}\n",
    "        iterated_power=iterated_power,  # int or \"auto\" (used by \"randomized\")\n",
    "        random_state=random_state\n",
    "    )\n",
    "    X_pca = pca.fit_transform(X_proc)\n",
    "\n",
    "    return (X_pca, pca) if return_model else X_pca\n",
    "\n",
    "# preform sparce PCA on a dataset \n",
    "def do_SPCA(X, n_components=2, alpha=1.0, ridge_alpha=0.01, max_iter=1000, tol=1e-8, method=\"sparse\", \n",
    "            batch_size=256, n_jobs=None, random_state=None, return_model = False):\n",
    "    \n",
    "    X_proc = X.values if isinstance(X, pd.DataFrame) else np.asarray(X)\n",
    "\n",
    "    # choose estimator\n",
    "    if method == \"minibatch\":\n",
    "        spca = MiniBatchSparsePCA(\n",
    "            n_components=n_components,  # int >= 1\n",
    "            alpha=alpha,                # float > 0 (ℓ1 sparsity strength)\n",
    "            ridge_alpha=ridge_alpha,    # float >= 0 (ridge penalty on codes)\n",
    "            n_jobs=n_jobs,\n",
    "            batch_size=batch_size,\n",
    "            max_iter=max_iter,\n",
    "            tol=tol,                    # float > 0\n",
    "            random_state=random_state\n",
    "        )\n",
    "    else:\n",
    "        spca = SparsePCA(\n",
    "            n_components=n_components,\n",
    "            alpha=alpha,\n",
    "            ridge_alpha=ridge_alpha,\n",
    "            n_jobs=n_jobs,\n",
    "            max_iter=max_iter,\n",
    "            tol=tol,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        \n",
    "    # fit + transform to get low-dim codes (scores)\n",
    "    Z = spca.fit_transform(X_proc)   # shape: (n_samples, n_components)\n",
    "\n",
    "    return (Z, spca) if return_model else Z\n",
    "\n",
    "\n",
    "def do_LLE(X, n_components=2, n_neighbors=10, method=\"standard\",\n",
    "            eigen_solver=\"auto\", reg=1e-3, random_state=None, n_jobs=None):\n",
    "    # ensure numpy array\n",
    "    X_proc = X.values if isinstance(X, pd.DataFrame) else np.asarray(X)\n",
    "\n",
    "    lle = LocallyLinearEmbedding(\n",
    "        n_neighbors=n_neighbors,    # int >= 2\n",
    "        n_components=n_components,  # int >=1\n",
    "        method=method,              # {\"standard\",\"modified\",\"hessian\",\"ltsa\"}\n",
    "        eigen_solver=eigen_solver,  # {\"auto\",\"arpack\",\"dense\"}\n",
    "        reg=reg,                    # float >= 0 (ridge for reconstruction)\n",
    "        random_state=random_state,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "\n",
    "    X_lle = lle.fit_transform(X_proc)\n",
    "    \n",
    "    return X_lle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d6ff4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the plotting function \n",
    "def plot_embeddings_grid(emb_dict, y, normalize=False, max_cols=3, figsize_per_plot=(5.2,4.2), s=28, alpha=0.9):\n",
    "    \"\"\"\n",
    "    emb_dict structure:\n",
    "      emb_dict[normalization_name][method_name] = {\"data\": 2D array, \"random_state\": int}\n",
    "\n",
    "    y: array-like labels (numeric or strings)\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Flatten items we will plot\n",
    "    items = []\n",
    "    for norm_name, methods in emb_dict.items():\n",
    "        for method_name, payload in methods.items():\n",
    "            if isinstance(payload, dict) and \"data\" in payload:\n",
    "                X2 = np.asarray(payload[\"data\"])\n",
    "                if X2.ndim == 2 and X2.shape[1] == 2:\n",
    "                    items.append((norm_name, method_name, X2, payload.get(\"random_state\", None)))\n",
    "    \n",
    "    # 2) Build a consistent label->color map across ALL subplots\n",
    "    y_arr = np.asarray(y)\n",
    "    seen = {}\n",
    "    for lbl in y_arr:\n",
    "        if lbl not in seen:\n",
    "            seen[lbl] = len(seen)\n",
    "    labels_order = list(seen.keys())\n",
    "\n",
    "    # Choose a fixed palette (expand if >10 classes)\n",
    "    base_colors = plt.rcParams['axes.prop_cycle'].by_key().get('color', ['C0','C1','C2','C3','C4','C5','C6','C7','C8','C9'])\n",
    "    if len(labels_order) > len(base_colors):\n",
    "        # repeat cycle if needed (rare for Iris)\n",
    "        repeats = int(np.ceil(len(labels_order)/len(base_colors)))\n",
    "        base_colors = (base_colors * repeats)[:len(labels_order)]\n",
    "    color_lookup = {lbl: base_colors[i] for i, lbl in enumerate(labels_order)}\n",
    "    cmap = ListedColormap([color_lookup[lbl] for lbl in labels_order])  # not used directly, kept for reference\n",
    "\n",
    "    # 3) Create grid\n",
    "    n_panels = len(items)\n",
    "    n_cols = min(max_cols, n_panels)\n",
    "    n_rows = int(np.ceil(n_panels / n_cols))\n",
    "    fig = plt.figure(figsize=(figsize_per_plot[0]*n_cols, figsize_per_plot[1]*n_rows))\n",
    "\n",
    "    # 4) Plot each embedding\n",
    "    for i, (norm_name, method_name, X2, seed) in enumerate(items, start=1):\n",
    "        ax = fig.add_subplot(n_rows, n_cols, i)\n",
    "        coords = X2 if not normalize else MinMaxScaler().fit_transform(X2)\n",
    "        for lbl in labels_order:\n",
    "            mask = (y_arr == lbl)\n",
    "            if np.any(mask):\n",
    "                ax.scatter(\n",
    "                    coords[mask, 0], coords[mask, 1],\n",
    "                    s=s, alpha=alpha, edgecolor=\"none\",\n",
    "                    c=[color_lookup[lbl]], label=str(lbl)\n",
    "                )\n",
    "\n",
    "        title = f\"{method_name} · {norm_name}\" + (f\" (seed={seed})\" if seed is not None else \"\")\n",
    "        ax.set_title(title, pad=10)\n",
    "        ax.set_xlabel(\"Dim 1\")\n",
    "        ax.set_ylabel(\"Dim 2\")\n",
    "        ax.set_aspect(\"equal\", adjustable=\"datalim\")\n",
    "        ax.grid(True, linewidth=0.3, alpha=0.4)\n",
    "\n",
    "        # show legend only on first subplot to reduce clutter\n",
    "        if i == 1:\n",
    "            ax.legend(frameon=True, title=\"Label\", loc=\"best\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51e3828",
   "metadata": {},
   "source": [
    "### Do PCA, and sparse PCA, t-SNE, UMAP, locally linear embedding (LLE) visualizations for Iris data under different normalization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff467fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first lets choose some normalization methods\n",
    "scalers = {\n",
    "    \"StandardScaler\": StandardScaler(),      # Baseline \n",
    "    \"MinMaxScaler\": MinMaxScaler(),          # defaults to [0,1]\n",
    "    \"RobustScaler\": RobustScaler(),          # median/IQR scaling\n",
    "    \"Normalizer(L2_rowwise)\": Normalizer()   # row-wise normalization (conceptually different)\n",
    "}\n",
    "\n",
    "scaled_data = {}\n",
    "for name, scaler in scalers.items():\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    scaled_data[f\"{name}-Data\"] = X_scaled\n",
    "\n",
    "# predicting that StandardScalar and MinMax will preform the best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b157888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducability use a random seed\n",
    "random_seed = 67\n",
    "iris_transformed = {}\n",
    "\n",
    "# get all of the data transformations after the normalizations\n",
    "for name, data in scaled_data.items():\n",
    "    iris_transformed[name] = {\n",
    "        \"PCA\": {\n",
    "            \"data\" : do_PCA(X=data, random_state=random_seed),\n",
    "            \"random_state\": random_seed\n",
    "        },\n",
    "        \"SPCA\": {\n",
    "            \"data\" : do_SPCA(X=data, random_state=random_seed),\n",
    "            \"random_state\": random_seed\n",
    "        },\n",
    "        \"tSNE\": {\n",
    "            \"data\" : do_tsne(X=data, random_state=random_seed),\n",
    "            \"random_state\": random_seed\n",
    "        },\n",
    "        \"UMAP\": {\n",
    "            \"data\" : do_UMAP(X=data, random_state=random_seed),\n",
    "            \"random_state\": random_seed\n",
    "        },\n",
    "        \"LLE\": {\n",
    "            \"data\" : do_LLE(X=data, random_state=random_seed),\n",
    "            \"random_state\": random_seed\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aece5b72",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along axis 0; size of axis is 150 but size of corresponding boolean axis is 3",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mplot_embeddings_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43miris_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[43m)\u001b[49m  \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mplot_embeddings_grid\u001b[39m\u001b[34m(emb_dict, y, normalize, max_cols, figsize_per_plot, s, alpha)\u001b[39m\n\u001b[32m     47\u001b[39m     mask = (y_arr == lbl)\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.any(mask):\n\u001b[32m     49\u001b[39m         ax.scatter(\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m             \u001b[43mcoords\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m, coords[mask, \u001b[32m1\u001b[39m],\n\u001b[32m     51\u001b[39m             s=s, alpha=alpha, edgecolor=\u001b[33m\"\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     52\u001b[39m             c=[color_lookup[lbl]], label=\u001b[38;5;28mstr\u001b[39m(lbl)\n\u001b[32m     53\u001b[39m         )\n\u001b[32m     55\u001b[39m title = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m · \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnorm_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m + (\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m (seed=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     56\u001b[39m ax.set_title(title, pad=\u001b[32m10\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: boolean index did not match indexed array along axis 0; size of axis is 150 but size of corresponding boolean axis is 3"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1560x2940 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_embeddings_grid(emb_dict=iris_transformed, y = target_names)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
